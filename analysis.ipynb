{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf4f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df14a197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title: Credit Approval\n",
      "\n",
      "2. Sources: \n",
      "\n",
      "    (confidential)\n",
      "\n",
      "    Submitted by quinlan@cs.su.oz.au\n",
      "\n",
      "3.  Past Usage:\n",
      "\n",
      "    See Quinlan,\n",
      "\n",
      "    * \"Simplifying decision trees\", Int J Man-Machine Studies 27,\n",
      "\n",
      "      Dec 1987, pp. 221-234.\n",
      "\n",
      "    * \"C4.5: Programs for Machine Learning\", Morgan Kaufmann, Oct 1992\n",
      "\n",
      "  \n",
      "\n",
      "4.  Relevant Information:\n",
      "\n",
      "    This file concerns credit card applications.  All attribute names\n",
      "\n",
      "    and values have been changed to meaningless symbols to protect\n",
      "\n",
      "    confidentiality of the data.\n",
      "\n",
      "  \n",
      "\n",
      "    This dataset is interesting because there is a good mix of\n",
      "\n",
      "    attributes -- continuous, nominal with small numbers of\n",
      "\n",
      "    values, and nominal with larger numbers of values.  There\n",
      "\n",
      "    are also a few missing values.\n",
      "\n",
      "  \n",
      "\n",
      "5.  Number of Instances: 690\n",
      "\n",
      "6.  Number of Attributes: 15 + class attribute\n",
      "\n",
      "7.  Attribute Information:\n",
      "\n",
      "    A1:\tb, a.\n",
      "\n",
      "    A2:\tcontinuous.\n",
      "\n",
      "    A3:\tcontinuous.\n",
      "\n",
      "    A4:\tu, y, l, t.\n",
      "\n",
      "    A5:\tg, p, gg.\n",
      "\n",
      "    A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
      "\n",
      "    A7:\tv, h, bb, j, n, z, dd, ff, o.\n",
      "\n",
      "    A8:\tcontinuous.\n",
      "\n",
      "    A9:\tt, f.\n",
      "\n",
      "    A10:\tt, f.\n",
      "\n",
      "    A11:\tcontinuous.\n",
      "\n",
      "    A12:\tt, f.\n",
      "\n",
      "    A13:\tg, p, s.\n",
      "\n",
      "    A14:\tcontinuous.\n",
      "\n",
      "    A15:\tcontinuous.\n",
      "\n",
      "    A16: +,-         (class attribute)\n",
      "\n",
      "8.  Missing Attribute Values:\n",
      "\n",
      "    37 cases (5%) have one or more missing values.  The missing\n",
      "\n",
      "    values from particular attributes are:\n",
      "\n",
      "    A1:  12\n",
      "\n",
      "    A2:  12\n",
      "\n",
      "    A4:   6\n",
      "\n",
      "    A5:   6\n",
      "\n",
      "    A6:   9\n",
      "\n",
      "    A7:   9\n",
      "\n",
      "    A14: 13\n",
      "\n",
      "9.  Class Distribution\n",
      "\n",
      "  \n",
      "\n",
      "    +: 307 (44.5%)\n",
      "\n",
      "    -: 383 (55.5%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metaFile = open(\"crx.names\", \"r\")\n",
    "for line in metaFile:\n",
    "    if(line != \"\\n\"):\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d387dd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>b</td>\n",
       "      <td>33.75</td>\n",
       "      <td>2.75</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>bb</td>\n",
       "      <td>0.00</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00180</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>a</td>\n",
       "      <td>24.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>678</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>b</td>\n",
       "      <td>19.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>m</td>\n",
       "      <td>bb</td>\n",
       "      <td>0.00</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>00500</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>b</td>\n",
       "      <td>37.75</td>\n",
       "      <td>7.00</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>11.50</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00300</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>b</td>\n",
       "      <td>29.25</td>\n",
       "      <td>13.00</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>0.50</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00228</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2     A3 A4 A5 A6  A7     A8 A9 A10  A11 A12 A13    A14  A15  T\n",
       "343  b  33.75   2.75  u  g  i  bb   0.00  f   f    0   f   g  00180    0  -\n",
       "200  a  24.08   0.50  u  g  q   h   1.25  t   t    1   f   g  00000  678  +\n",
       "318  b  19.17   0.00  y  p  m  bb   0.00  f   f    0   t   s  00500    1  +\n",
       "116  b  37.75   7.00  u  g  q   h  11.50  t   t    7   t   g  00300    5  -\n",
       "628  b  29.25  13.00  u  g  d   h   0.50  f   f    0   f   g  00228    0  -"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"crx.csv\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f279b198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1      object\n",
      "A2      object\n",
      "A3     float64\n",
      "A4      object\n",
      "A5      object\n",
      "A6      object\n",
      "A7      object\n",
      "A8     float64\n",
      "A9      object\n",
      "A10     object\n",
      "A11      int64\n",
      "A12     object\n",
      "A13     object\n",
      "A14     object\n",
      "A15      int64\n",
      "T       object\n",
      "dtype: object\n",
      "\n",
      "(690, 16)\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "print()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7cd1bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 : ['b' 'a' '?']\n",
      "A2 : ['30.83' '58.67' '24.50' '27.83' '20.17' '32.08' '33.17' '22.92' '54.42'\n",
      " '42.50' '22.08' '29.92' '38.25' '48.08' '45.83' '36.67' '28.25' '23.25'\n",
      " '21.83' '19.17' '25.00' '47.75' '27.42' '41.17' '15.83' '47.00' '56.58'\n",
      " '57.42' '42.08' '29.25' '42.00' '49.50' '36.75' '22.58' '27.25' '23.00'\n",
      " '27.75' '54.58' '34.17' '28.92' '29.67' '39.58' '56.42' '54.33' '41.00'\n",
      " '31.92' '41.50' '23.92' '25.75' '26.00' '37.42' '34.92' '34.25' '23.33'\n",
      " '23.17' '44.33' '35.17' '43.25' '56.75' '31.67' '23.42' '20.42' '26.67'\n",
      " '36.00' '25.50' '19.42' '32.33' '34.83' '38.58' '44.25' '44.83' '20.67'\n",
      " '34.08' '21.67' '21.50' '49.58' '27.67' '39.83' '?' '37.17' '25.67'\n",
      " '34.00' '49.00' '62.50' '31.42' '52.33' '28.75' '28.58' '22.50' '28.50'\n",
      " '37.50' '35.25' '18.67' '54.83' '40.92' '19.75' '29.17' '24.58' '33.75'\n",
      " '25.42' '37.75' '52.50' '57.83' '20.75' '39.92' '24.75' '44.17' '23.50'\n",
      " '47.67' '22.75' '34.42' '28.42' '67.75' '47.42' '36.25' '32.67' '48.58'\n",
      " '33.58' '18.83' '26.92' '31.25' '56.50' '43.00' '22.33' '32.83' '40.33'\n",
      " '30.50' '52.83' '46.67' '58.33' '37.33' '23.08' '32.75' '68.67' '28.00'\n",
      " '44.00' '25.08' '32.00' '60.58' '40.83' '19.33' '41.33' '56.00' '49.83'\n",
      " '22.67' '27.00' '26.08' '18.42' '21.25' '57.08' '22.42' '48.75' '40.00'\n",
      " '40.58' '28.67' '33.08' '21.33' '41.75' '34.50' '48.17' '27.58' '24.08'\n",
      " '24.83' '36.33' '35.42' '71.58' '39.50' '39.33' '24.33' '60.08' '55.92'\n",
      " '53.92' '18.92' '50.08' '65.42' '17.58' '18.08' '19.67' '25.17' '33.50'\n",
      " '58.42' '26.17' '42.83' '38.17' '20.50' '48.25' '28.33' '18.75' '18.50'\n",
      " '45.00' '40.25' '41.42' '17.83' '18.17' '20.00' '52.17' '50.75' '17.08'\n",
      " '18.33' '59.67' '18.00' '37.58' '30.67' '18.58' '16.25' '21.17' '17.67'\n",
      " '16.50' '29.50' '21.75' '18.25' '35.75' '16.08' '69.17' '32.92' '16.33'\n",
      " '22.17' '57.58' '15.92' '31.75' '19.00' '17.50' '33.67' '30.17' '33.25'\n",
      " '25.25' '34.75' '47.33' '39.08' '42.75' '38.92' '62.75' '32.25' '26.75'\n",
      " '63.33' '30.75' '16.00' '19.50' '32.42' '30.25' '26.83' '16.92' '24.42'\n",
      " '39.42' '23.58' '21.42' '33.00' '26.33' '26.25' '28.17' '20.83' '43.17'\n",
      " '56.83' '15.17' '29.83' '31.00' '51.92' '69.50' '19.58' '22.25' '38.42'\n",
      " '26.58' '35.00' '29.42' '49.17' '51.83' '58.58' '53.33' '27.17' '25.92'\n",
      " '30.58' '17.25' '27.33' '36.50' '29.75' '52.42' '36.17' '34.58' '21.92'\n",
      " '36.58' '31.08' '30.42' '21.08' '17.42' '39.17' '26.50' '17.33' '23.75'\n",
      " '34.67' '74.83' '45.33' '47.25' '24.17' '39.25' '39.00' '64.08' '31.33'\n",
      " '21.00' '13.75' '46.00' '20.25' '60.92' '30.00' '22.83' '45.17' '41.58'\n",
      " '55.75' '25.33' '31.83' '33.92' '24.92' '80.25' '30.08' '48.33' '76.75'\n",
      " '51.33' '41.92' '29.58' '32.17' '51.42' '42.17' '43.08' '59.50' '65.17'\n",
      " '20.33' '48.50' '28.08' '73.42' '51.58' '38.67' '46.08' '20.08' '42.25'\n",
      " '16.17' '47.83' '22.00' '38.33' '25.58' '21.58' '36.08' '38.75' '35.58'\n",
      " '31.58' '15.75' '17.92' '30.33' '47.17' '25.83' '50.25' '36.42']\n",
      "A3 : [ 0.     4.46   0.5    1.54   5.625  4.     1.04  11.585  4.915  0.83\n",
      "  1.835  6.     6.04  10.5    4.415  0.875  5.875  0.25   8.585 11.25\n",
      "  1.     8.    14.5    6.5    0.585 13.    18.5    8.5   14.79   9.79\n",
      "  7.585  5.125 10.75   1.5    1.585 11.75   9.415  9.17  15.     1.415\n",
      " 13.915 28.     6.75   2.04   0.665  2.5    3.    11.625  4.5   12.25\n",
      " 16.165  0.79   0.835  4.25   0.375 25.125  7.5    5.     7.     5.29\n",
      "  1.165  9.75  19.     3.5    0.625  2.21  12.75  15.5    1.375  3.54\n",
      " 11.     1.75  16.5   12.     2.25   0.75  12.5    1.25   1.125  7.04\n",
      " 10.335  6.21   6.665  9.     5.5    0.54   2.75   9.5   13.5    3.75\n",
      " 16.     0.29   1.665  7.54   0.46  10.    11.5    3.04   2.     0.08\n",
      "  1.71   3.25   2.54  13.585  8.665  9.25   8.17   2.335 19.5    5.665\n",
      "  4.625  0.205  0.96   4.04   5.04   3.165  7.625 10.04  10.25   2.125\n",
      "  9.335  6.625  2.71   9.625 12.54   9.54   8.46  13.75  21.    10.125\n",
      " 25.085  0.21  21.5   11.125 11.045  1.335  0.085  1.21   0.165  5.71\n",
      "  5.415 12.625  0.58   0.415  2.415  0.335  3.125 12.125  2.875 13.665\n",
      " 26.335 10.29   1.29  22.     0.125  1.085  4.085  4.71   6.165  4.585\n",
      " 11.46  14.585  0.17   1.625  2.085  5.085  8.125  2.835  1.79   0.705\n",
      "  2.165  2.29  18.125  3.085 11.665  4.125  1.08  13.335 11.835  4.79\n",
      "  9.96   7.08  25.21   0.67   3.79  22.29   3.335  0.42   1.46   0.04\n",
      " 12.33  12.335  0.915 14.    17.75  20.     5.25   4.165 10.915  4.75\n",
      " 10.415  7.835  0.71   2.46   9.585  3.625  2.665  5.835 12.835 10.665\n",
      "  7.25  10.21   3.29  10.085  3.375]\n",
      "A4 : ['u' 'y' '?' 'l']\n",
      "A5 : ['g' 'p' '?' 'gg']\n",
      "A6 : ['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j' '?']\n",
      "A7 : ['v' 'h' 'bb' 'ff' 'j' 'z' '?' 'o' 'dd' 'n']\n",
      "A8 : [ 1.25   3.04   1.5    3.75   1.71   2.5    6.5    0.04   3.96   3.165\n",
      "  2.165  4.335  1.     5.     0.25   0.96   3.17   0.665  0.75   0.835\n",
      "  7.875  3.085  0.5    5.165 15.     7.     5.04   7.96   7.585  0.415\n",
      "  2.     1.835 14.415  4.5    5.335  8.625 28.5    2.625  0.125  6.04\n",
      "  3.5    0.165  0.875  1.75   0.     7.415  0.085  5.75   6.     3.\n",
      "  1.585  4.29   1.54   1.46   1.625 12.5   13.5   10.75   0.375  0.585\n",
      "  0.455  4.     8.5    9.46   2.25  10.     0.795  1.375  1.29  11.5\n",
      "  6.29  14.     0.335  1.21   7.375  7.5    3.25  13.     5.5    4.25\n",
      "  0.625  5.085  2.75   2.375  8.     1.085  2.54   4.165  1.665 11.\n",
      "  9.     1.335  1.415  1.96   2.585  5.125 15.5    0.71   5.665 18.\n",
      "  5.25   8.665  2.29  20.     2.46  13.875  2.085  4.58   2.71   2.04\n",
      "  0.29   4.75   0.46   0.21   0.54   3.335  2.335  1.165  2.415  2.79\n",
      "  4.625  1.04   6.75   1.875 16.    12.75   5.375  2.125 17.5    3.125\n",
      "  0.79   8.29 ]\n",
      "A9 : ['t' 'f']\n",
      "A10 : ['t' 'f']\n",
      "A11 : [ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n",
      "A12 : ['f' 't']\n",
      "A13 : ['g' 's' 'p']\n",
      "A14 : ['00202' '00043' '00280' '00100' '00120' '00360' '00164' '00080' '00180'\n",
      " '00052' '00128' '00260' '00000' '00320' '00396' '00096' '00200' '00300'\n",
      " '00145' '00500' '00168' '00434' '00583' '00030' '00240' '00070' '00455'\n",
      " '00311' '00216' '00491' '00400' '00239' '00160' '00711' '00250' '00520'\n",
      " '00515' '00420' '?' '00980' '00443' '00140' '00094' '00368' '00288'\n",
      " '00928' '00188' '00112' '00171' '00268' '00167' '00075' '00152' '00176'\n",
      " '00329' '00212' '00410' '00274' '00375' '00408' '00350' '00204' '00040'\n",
      " '00181' '00399' '00440' '00093' '00060' '00395' '00393' '00021' '00029'\n",
      " '00102' '00431' '00370' '00024' '00020' '00129' '00510' '00195' '00144'\n",
      " '00380' '00049' '00050' '00381' '00150' '00117' '00056' '00211' '00230'\n",
      " '00156' '00022' '00228' '00519' '00253' '00487' '00220' '00088' '00073'\n",
      " '00121' '00470' '00136' '00132' '00292' '00154' '00272' '00340' '00108'\n",
      " '00720' '00450' '00232' '00170' '01160' '00411' '00460' '00348' '00480'\n",
      " '00640' '00372' '00276' '00221' '00352' '00141' '00178' '00600' '00550'\n",
      " '02000' '00225' '00210' '00110' '00356' '00045' '00062' '00092' '00174'\n",
      " '00017' '00086' '00454' '00254' '00028' '00263' '00333' '00312' '00290'\n",
      " '00371' '00099' '00252' '00760' '00560' '00130' '00523' '00680' '00163'\n",
      " '00208' '00383' '00330' '00422' '00840' '00432' '00032' '00186' '00303'\n",
      " '00349' '00224' '00369' '00076' '00231' '00309' '00416' '00465' '00256']\n",
      "A15 : [     0    560    824      3  31285   1349    314   1442    200   2690\n",
      "    245   1208   1260     11  10000   5000   4000     35    713    551\n",
      "    500    300    221   2283    100     15    284   1236   5800    730\n",
      "    400  50000    456  15108   2954      2     20     27    225      1\n",
      "     38      5    130    147    210  11202   1332     50    258    567\n",
      "   1000   2510    809    610    150  51100    367    600    247    375\n",
      "    278    827   2072    582   2300   3065   2200      6   1602   2184\n",
      "   3376   2000   7544  10561    837  11177    639   2028   1065    540\n",
      "    158  15000   3000   3257   1655   1430      7    790    396    678\n",
      "   1187   6590    168   1270   1210    742   8851   7059   1704    857\n",
      "   6700   2503   9800    196     14  26726  18027     99    444   1200\n",
      "   2010     13    120     32    722     40    484    204     98   5552\n",
      "    105   2803    126      4     21    173     10     25     42 100000\n",
      "    113      8     44   2732    179     16   1062    251    228     67\n",
      "     12    122   4208   1300    112   1110   1004    286   4500   1212\n",
      "    195     87     17    184    140     18    146     22     55     70\n",
      "     60   1058    769   5200     19    316    350   3552    687   1950\n",
      "     53     41     33     80    351   2100    475    892   4607   2206\n",
      "   5860     28   1391   2279    591    960    690    234    800    990\n",
      "   2197     90    340    347    327   4071    109   1249    134   1344\n",
      "    321    948   2079   2384    458   5298    162   1583     58     59\n",
      "   1400   1465   8000   4700   1097   3290  13212   5777   5124     23\n",
      "   4159    918    768    283    108      9     68    587    141    501\n",
      "    160    390    154    117    246    237    364    537    394    750]\n",
      "T : ['+' '-']\n"
     ]
    }
   ],
   "source": [
    "for column in df:\n",
    "    print(f'{column} : {df[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6049ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[(df.A1 != '?') & (df.A2 != '?') & (df.A4 != '?') & (df.A5 != '?') & (df.A6 != '?') & (df.A7 != '?') & (df.A14 != '?')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c816cfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(653, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3102f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 : ['b' 'a']\n",
      "A2 : ['30.83' '58.67' '24.50' '27.83' '20.17' '32.08' '33.17' '22.92' '54.42'\n",
      " '42.50' '22.08' '29.92' '38.25' '48.08' '45.83' '36.67' '28.25' '23.25'\n",
      " '21.83' '19.17' '25.00' '47.75' '27.42' '41.17' '15.83' '47.00' '56.58'\n",
      " '57.42' '42.08' '29.25' '42.00' '49.50' '36.75' '22.58' '27.25' '23.00'\n",
      " '27.75' '54.58' '34.17' '28.92' '29.67' '39.58' '56.42' '54.33' '41.00'\n",
      " '31.92' '41.50' '23.92' '25.75' '26.00' '37.42' '34.92' '34.25' '23.33'\n",
      " '23.17' '44.33' '35.17' '43.25' '56.75' '31.67' '23.42' '20.42' '26.67'\n",
      " '36.00' '25.50' '19.42' '32.33' '38.58' '44.25' '44.83' '20.67' '34.08'\n",
      " '21.67' '21.50' '49.58' '27.67' '39.83' '37.17' '25.67' '34.00' '49.00'\n",
      " '62.50' '31.42' '52.33' '28.75' '28.58' '22.50' '28.50' '37.50' '35.25'\n",
      " '18.67' '54.83' '40.92' '19.75' '29.17' '24.58' '33.75' '25.42' '37.75'\n",
      " '52.50' '57.83' '20.75' '39.92' '24.75' '44.17' '23.50' '47.67' '22.75'\n",
      " '34.42' '28.42' '67.75' '47.42' '36.25' '32.67' '48.58' '33.58' '18.83'\n",
      " '26.92' '31.25' '56.50' '43.00' '22.33' '32.83' '40.33' '30.50' '52.83'\n",
      " '46.67' '58.33' '37.33' '23.08' '32.75' '68.67' '28.00' '44.00' '25.08'\n",
      " '32.00' '60.58' '40.83' '19.33' '41.33' '56.00' '49.83' '22.67' '27.00'\n",
      " '26.08' '18.42' '21.25' '57.08' '22.42' '48.75' '40.00' '40.58' '28.67'\n",
      " '33.08' '21.33' '41.75' '34.50' '48.17' '27.58' '24.08' '36.33' '35.42'\n",
      " '39.50' '39.33' '24.33' '60.08' '55.92' '53.92' '18.92' '50.08' '65.42'\n",
      " '17.58' '18.08' '19.67' '25.17' '33.50' '58.42' '26.17' '42.83' '38.17'\n",
      " '20.50' '48.25' '28.33' '18.50' '45.00' '40.25' '41.42' '17.83' '18.17'\n",
      " '20.00' '52.17' '50.75' '17.08' '18.33' '59.67' '18.00' '30.67' '18.58'\n",
      " '16.25' '21.17' '17.67' '16.50' '29.50' '21.75' '18.25' '35.75' '16.08'\n",
      " '69.17' '32.92' '16.33' '22.17' '57.58' '15.92' '31.75' '24.83' '19.00'\n",
      " '17.50' '33.67' '30.17' '34.83' '33.25' '25.25' '34.75' '47.33' '39.08'\n",
      " '42.75' '38.92' '62.75' '26.75' '63.33' '30.75' '16.00' '19.50' '32.42'\n",
      " '30.25' '26.83' '16.92' '24.42' '39.42' '23.58' '21.42' '33.00' '26.33'\n",
      " '26.25' '20.83' '43.17' '56.83' '15.17' '29.83' '31.00' '51.92' '69.50'\n",
      " '19.58' '22.25' '38.42' '26.58' '35.00' '29.42' '49.17' '51.83' '58.58'\n",
      " '53.33' '27.17' '25.92' '30.58' '17.25' '27.33' '36.50' '52.42' '36.17'\n",
      " '21.92' '36.58' '31.08' '30.42' '21.08' '17.42' '39.17' '17.33' '23.75'\n",
      " '34.67' '74.83' '28.17' '47.25' '24.17' '39.25' '39.00' '64.08' '31.33'\n",
      " '21.00' '13.75' '46.00' '20.25' '60.92' '30.00' '22.83' '45.17' '41.58'\n",
      " '55.75' '25.33' '31.83' '33.92' '24.92' '30.08' '48.33' '76.75' '51.33'\n",
      " '41.92' '29.58' '32.17' '51.42' '42.17' '43.08' '59.50' '65.17' '20.33'\n",
      " '32.25' '48.50' '28.08' '73.42' '51.58' '38.67' '46.08' '20.08' '16.17'\n",
      " '47.83' '22.00' '38.33' '21.58' '36.08' '38.75' '35.58' '31.58' '25.58'\n",
      " '15.75' '17.92' '30.33' '47.17' '25.83' '50.25' '36.42']\n",
      "A3 : [ 0.     4.46   0.5    1.54   5.625  4.     1.04  11.585  4.915  0.83\n",
      "  1.835  6.     6.04  10.5    4.415  0.875  5.875  0.25   8.585 11.25\n",
      "  1.     8.    14.5    6.5    0.585 13.    18.5    8.5   14.79   9.79\n",
      "  7.585  5.125 10.75   1.5    1.585 11.75   9.415  9.17  15.     1.415\n",
      " 13.915 28.     6.75   2.04   0.665  2.5    3.    11.625  4.5   12.25\n",
      " 16.165  0.79   0.835  4.25   0.375 25.125  7.5    5.     7.     5.29\n",
      "  1.165  9.75  19.     0.625  2.21  12.75  15.5    1.375  3.54  11.\n",
      "  1.75  16.5   12.     2.25   0.75   3.5   12.5    1.25   1.125  7.04\n",
      " 10.335  6.21   6.665  9.     5.5    0.54   2.75   9.5   13.5    3.75\n",
      " 16.     0.29   1.665  7.54   0.46  10.    11.5    3.04   2.     0.08\n",
      "  1.71   3.25   2.54  13.585  8.665  9.25   8.17   2.335 19.5    5.665\n",
      "  4.625  0.205  0.96   4.04   5.04   3.165  7.625 10.04  10.25   2.125\n",
      "  9.335  6.625  2.71   9.625 12.54   9.54   8.46  13.75  21.    10.125\n",
      " 25.085  0.21  21.5   11.125 11.045  1.335  0.085  1.21   0.165  5.71\n",
      "  5.415 12.625  0.58   0.415  2.415  0.335  3.125 12.125  2.875 13.665\n",
      " 26.335 10.29   1.29  22.     0.125  1.085  4.085  4.71   6.165  4.585\n",
      " 11.46  14.585  0.17   1.625  2.085  5.085  2.835  1.79   0.705  2.165\n",
      "  2.29  18.125  3.085 11.665  4.125  1.08  13.335 11.835  4.79   9.96\n",
      "  7.08  25.21   0.67   3.79  22.29   3.335  0.42   1.46   0.04  12.33\n",
      " 12.335  0.915 14.    17.75  20.     5.25   4.165 10.915  4.75  10.415\n",
      "  0.71   2.46   9.585  3.625  2.665  5.835 12.835 10.665  7.25  10.21\n",
      "  3.29  10.085  3.375]\n",
      "A4 : ['u' 'y' 'l']\n",
      "A5 : ['g' 'p' 'gg']\n",
      "A6 : ['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j']\n",
      "A7 : ['v' 'h' 'bb' 'ff' 'j' 'z' 'o' 'dd' 'n']\n",
      "A8 : [ 1.25   3.04   1.5    3.75   1.71   2.5    6.5    0.04   3.96   3.165\n",
      "  2.165  4.335  1.     5.     0.25   0.96   3.17   0.665  0.75   0.835\n",
      "  7.875  3.085  0.5    5.165 15.     7.     5.04   7.96   7.585  0.415\n",
      "  2.     1.835 14.415  4.5    5.335  8.625 28.5    2.625  0.125  6.04\n",
      "  3.5    0.165  0.875  1.75   0.     7.415  0.085  5.75   6.     3.\n",
      "  1.585  4.29   1.54   1.46   1.625 13.5   10.75   0.375  0.585  0.455\n",
      "  4.     9.46   2.25  10.     0.795  1.375  1.29  11.5    6.29  14.\n",
      "  0.335  1.21   7.375  8.5    7.5    3.25  13.     5.5    4.25   0.625\n",
      "  5.085  2.75   2.375  8.     1.085  2.54   4.165  1.665 11.     9.\n",
      "  1.335  1.415  1.96   2.585 12.5    5.125 15.5    0.71   5.665 18.\n",
      "  5.25   8.665  2.29  20.     2.46  13.875  2.085  4.58   2.04   0.29\n",
      "  0.46   0.21   0.54   3.335  2.335  1.165  2.415  2.79   4.625  1.04\n",
      "  4.75   6.75   1.875 16.    12.75   5.375  2.125 17.5    3.125  0.79\n",
      "  8.29 ]\n",
      "A9 : ['t' 'f']\n",
      "A10 : ['t' 'f']\n",
      "A11 : [ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n",
      "A12 : ['f' 't']\n",
      "A13 : ['g' 's' 'p']\n",
      "A14 : ['00202' '00043' '00280' '00100' '00120' '00360' '00164' '00080' '00180'\n",
      " '00052' '00128' '00260' '00000' '00320' '00396' '00096' '00200' '00300'\n",
      " '00145' '00500' '00168' '00434' '00583' '00030' '00240' '00070' '00455'\n",
      " '00311' '00216' '00491' '00400' '00239' '00160' '00711' '00250' '00520'\n",
      " '00515' '00420' '00980' '00443' '00140' '00094' '00368' '00288' '00188'\n",
      " '00112' '00171' '00268' '00167' '00075' '00152' '00176' '00329' '00212'\n",
      " '00410' '00274' '00375' '00408' '00350' '00204' '00040' '00181' '00399'\n",
      " '00440' '00093' '00060' '00395' '00393' '00021' '00029' '00102' '00431'\n",
      " '00370' '00024' '00020' '00129' '00510' '00195' '00144' '00380' '00049'\n",
      " '00050' '00381' '00150' '00117' '00056' '00211' '00230' '00156' '00022'\n",
      " '00228' '00519' '00253' '00487' '00220' '00088' '00121' '00470' '00136'\n",
      " '00132' '00292' '00154' '00272' '00340' '00108' '00720' '00450' '00232'\n",
      " '00170' '00460' '00348' '00480' '00640' '00276' '00221' '00352' '00141'\n",
      " '00178' '00600' '00550' '00073' '02000' '00225' '00210' '00110' '00356'\n",
      " '00045' '00062' '00092' '00174' '00017' '00086' '00454' '00254' '00028'\n",
      " '00333' '00312' '00371' '00099' '00252' '00760' '00560' '00130' '00523'\n",
      " '00680' '00163' '00208' '00383' '00330' '00422' '00290' '00840' '00432'\n",
      " '00032' '00186' '00303' '00349' '00224' '00369' '00076' '00231' '00309'\n",
      " '00416' '00465']\n",
      "A15 : [     0    560    824      3  31285   1349    314   1442    200   2690\n",
      "    245   1208   1260     11  10000   5000   4000     35    713    551\n",
      "    500    300    221   2283    100     15    284   1236   5800    730\n",
      "    400  50000    456  15108   2954      2     20     27    225      1\n",
      "     38      5    130    147    210  11202   1332     50    258    567\n",
      "   1000   2510    809    610    150  51100    367    600    247    375\n",
      "    278    827   2072    582   2300   3065   2200      6   1602   2184\n",
      "   3376   2000   7544  10561    837  11177    639   2028   1065    540\n",
      "    158  15000   3000   3257   1655   1430      7    790    396    678\n",
      "   1187   6590    168   1270   1210    742   8851   7059   1704    857\n",
      "   6700   2503   9800    196     14  18027     99   1200     13    120\n",
      "     32    722     40    484    204     98   5552   2803    444    126\n",
      "      4     21    173     10     25     42 100000    113      8     44\n",
      "   2732    179     16   1062    251    228     67     12   4208   1300\n",
      "    112   1110    286   4500   1212    195     87     17    184    140\n",
      "    146     22     55     70     60   1058    769     19    316    350\n",
      "   3552    687   1950     18     53     41     33     80    351   2100\n",
      "    475    892   4607   2206   5860     28   1391    591    960    690\n",
      "    800    990   2197     90    347    327   4071    109   1249    134\n",
      "   1344    321    948   2079   2384    458   5298    162   1583     58\n",
      "     59   1400   1465   8000   4700   1097   3290  13212   5777   5124\n",
      "     23   4159    918    283    108      9     68    587    501    160\n",
      "    390    154    117    246    237    364    537    394    750]\n",
      "T : ['+' '-']\n"
     ]
    }
   ],
   "source": [
    "for column in df1:\n",
    "    print(f'{column} : {df1[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff9d67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashan_105579\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df1.A2 = pd.to_numeric(df1.A2)\n",
    "df1.A14 = pd.to_numeric(df1.A14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d4afc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1      object\n",
       "A2     float64\n",
       "A3     float64\n",
       "A4      object\n",
       "A5      object\n",
       "A6      object\n",
       "A7      object\n",
       "A8     float64\n",
       "A9      object\n",
       "A10     object\n",
       "A11      int64\n",
       "A12     object\n",
       "A13     object\n",
       "A14      int64\n",
       "A15      int64\n",
       "T       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f8c178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>a</td>\n",
       "      <td>47.25</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>2.750</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>333</td>\n",
       "      <td>892</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>b</td>\n",
       "      <td>41.75</td>\n",
       "      <td>0.960</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>x</td>\n",
       "      <td>v</td>\n",
       "      <td>2.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>510</td>\n",
       "      <td>600</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>b</td>\n",
       "      <td>22.67</td>\n",
       "      <td>1.585</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.085</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>b</td>\n",
       "      <td>36.33</td>\n",
       "      <td>2.125</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>0.085</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>50</td>\n",
       "      <td>1187</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>b</td>\n",
       "      <td>24.50</td>\n",
       "      <td>13.335</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>120</td>\n",
       "      <td>475</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>b</td>\n",
       "      <td>40.00</td>\n",
       "      <td>6.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>bb</td>\n",
       "      <td>3.500</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>a</td>\n",
       "      <td>39.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>3.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>b</td>\n",
       "      <td>32.33</td>\n",
       "      <td>3.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>a</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.625</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>40</td>\n",
       "      <td>600</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>b</td>\n",
       "      <td>19.17</td>\n",
       "      <td>9.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.500</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>120</td>\n",
       "      <td>2206</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A1     A2      A3 A4 A5  A6  A7     A8 A9 A10  A11 A12 A13  A14   A15  T\n",
       "490  a  47.25   0.750  u  g   q   h  2.750  t   t    1   f   g  333   892  +\n",
       "192  b  41.75   0.960  u  g   x   v  2.500  t   f    0   f   g  510   600  +\n",
       "193  b  22.67   1.585  y  p   w   v  3.085  t   t    6   f   g   80     0  +\n",
       "204  b  36.33   2.125  y  p   w   v  0.085  t   t    1   f   g   50  1187  +\n",
       "487  b  24.50  13.335  y  p  aa   v  0.040  f   f    0   t   g  120   475  -\n",
       "186  b  40.00   6.500  u  g  aa  bb  3.500  t   t    1   f   g    0   500  +\n",
       "340  a  39.08   4.000  u  g   c   v  3.000  f   f    0   f   g  480     0  -\n",
       "607  b  32.33   3.500  u  g   k   v  0.500  f   f    0   t   g  232     0  -\n",
       "138  a  18.83   9.500  u  g   w   v  1.625  t   t    6   t   g   40   600  +\n",
       "495  b  19.17   9.500  u  g   w   v  1.500  t   f    0   f   g  120  2206  +"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed99622",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashan_105579\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df1['A1'].replace({'b': 1,'a': 0},inplace=True)\n",
    "df1['A9'].replace({'t': 1,'f': 0},inplace=True)\n",
    "df1['A10'].replace({'t': 1,'f': 0},inplace=True)\n",
    "df1['A12'].replace({'t': 1,'f': 0},inplace=True)\n",
    "df1['T'].replace({'+': 1,'-': 0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a91a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1       int64\n",
       "A2     float64\n",
       "A3     float64\n",
       "A4      object\n",
       "A5      object\n",
       "A6      object\n",
       "A7      object\n",
       "A8     float64\n",
       "A9       int64\n",
       "A10      int64\n",
       "A11      int64\n",
       "A12      int64\n",
       "A13     object\n",
       "A14      int64\n",
       "A15      int64\n",
       "T        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13529eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1</td>\n",
       "      <td>48.58</td>\n",
       "      <td>0.205</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>380</td>\n",
       "      <td>2732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>27.25</td>\n",
       "      <td>1.585</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>h</td>\n",
       "      <td>1.835</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>583</td>\n",
       "      <td>713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>27.58</td>\n",
       "      <td>2.040</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>370</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1.125</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>18.42</td>\n",
       "      <td>9.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>1.210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>60</td>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2     A3 A4 A5  A6 A7     A8  A9  A10  A11  A12 A13  A14   A15  T\n",
       "323   1  48.58  0.205  y  p   k  v  0.250   1    1   11    0   g  380  2732  1\n",
       "36    1  27.25  1.585  u  g  cc  h  1.835   1    1   12    1   g  583   713  1\n",
       "198   1  27.58  2.040  y  p  aa  v  2.000   1    1    3    1   g  370   560  1\n",
       "169   1  37.50  1.125  y  p   d  v  1.500   0    0    0    1   g  431     0  1\n",
       "178   0  18.42  9.250  u  g   q  v  1.210   1    1    4    0   g   60   540  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae08247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8463cc564716>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[i] = df1[i].astype('category')\n",
      "<ipython-input-15-8463cc564716>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[i] = df1[i].cat.codes\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['A4', 'A5', 'A6', 'A7', 'A13']\n",
    "for i in categorical_columns:\n",
    "    df1[i] = df1[i].astype('category')\n",
    "    df1[i] = df1[i].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac3369f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1       int64\n",
       "A2     float64\n",
       "A3     float64\n",
       "A4        int8\n",
       "A5        int8\n",
       "A6        int8\n",
       "A7        int8\n",
       "A8     float64\n",
       "A9       int64\n",
       "A10      int64\n",
       "A11      int64\n",
       "A12      int64\n",
       "A13       int8\n",
       "A14      int64\n",
       "A15      int64\n",
       "T        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb7d90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>25.17</td>\n",
       "      <td>3.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "      <td>17.08</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>33.17</td>\n",
       "      <td>3.165</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3.165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>8.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>5860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>25.00</td>\n",
       "      <td>12.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>48.58</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0</td>\n",
       "      <td>46.67</td>\n",
       "      <td>0.460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "      <td>32.00</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>37.75</td>\n",
       "      <td>5.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6  A7     A8  A9  A10  A11  A12  A13  A14  \\\n",
       "230   1  25.17   3.500   1   0   2   7  0.625   1    1    7    0    0    0   \n",
       "409   1  17.08   0.250   1   0  10   7  0.335   0    1    4    0    0  160   \n",
       "196   1  33.17   3.165   2   2  13   7  3.165   1    1    3    1    0  380   \n",
       "523   0  22.50   8.500   1   0  10   7  1.750   1    1   10    0    0   80   \n",
       "496   0  25.00   0.875   1   0  13   3  1.040   1    0    0    1    0  160   \n",
       "176   1  25.00  12.500   1   0   0   7  3.000   1    0    0    1    2   20   \n",
       "135   1  48.58   6.500   1   0  10   3  6.000   1    0    0    1    0  350   \n",
       "150   0  46.67   0.460   1   0   2   3  0.415   1    1   11    1    0  440   \n",
       "267   0  32.00   6.000   1   0   3   7  1.250   0    0    0    0    0  272   \n",
       "224   0  37.75   5.500   1   0  10   7  0.125   1    0    0    1    0  228   \n",
       "\n",
       "      A15  T  \n",
       "230  7059  1  \n",
       "409     8  0  \n",
       "196     0  1  \n",
       "523   990  0  \n",
       "496  5860  1  \n",
       "176     0  1  \n",
       "135     0  1  \n",
       "150     6  1  \n",
       "267     0  0  \n",
       "224     0  1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68fa55ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-7e0ffb381c07>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])\n",
      "C:\\Users\\ashan_105579\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "cols_to_scale = ['A2','A3','A8', 'A14', 'A15']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7205cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1 : [1 0]\n",
      "A2 : [0.27111111 0.71301587 0.17063492 0.22349206 0.10190476 0.29095238\n",
      " 0.30825397 0.14555556 0.64555556 0.45634921 0.13222222 0.25666667\n",
      " 0.38888889 0.54492063 0.50920635 0.36380952 0.23015873 0.15079365\n",
      " 0.12825397 0.08603175 0.17857143 0.53968254 0.21698413 0.4352381\n",
      " 0.03301587 0.52777778 0.67984127 0.6931746  0.44968254 0.24603175\n",
      " 0.4484127  0.56746032 0.36507937 0.14015873 0.21428571 0.1468254\n",
      " 0.22222222 0.64809524 0.32412698 0.24079365 0.25269841 0.41\n",
      " 0.67730159 0.64412698 0.43253968 0.2884127  0.44047619 0.16142857\n",
      " 0.19047619 0.19444444 0.37571429 0.33603175 0.32539683 0.15206349\n",
      " 0.14952381 0.48539683 0.34       0.46825397 0.68253968 0.28444444\n",
      " 0.15349206 0.10587302 0.20507937 0.3531746  0.18650794 0.09\n",
      " 0.29492063 0.39412698 0.48412698 0.49333333 0.10984127 0.32269841\n",
      " 0.12571429 0.12301587 0.56873016 0.22095238 0.41396825 0.37174603\n",
      " 0.18920635 0.32142857 0.55952381 0.77380952 0.28047619 0.61238095\n",
      " 0.23809524 0.23539683 0.13888889 0.23412698 0.37698413 0.34126984\n",
      " 0.07809524 0.65206349 0.43126984 0.0952381  0.2447619  0.17190476\n",
      " 0.31746032 0.1852381  0.38095238 0.61507937 0.69968254 0.11111111\n",
      " 0.41539683 0.17460317 0.48285714 0.1547619  0.5384127  0.14285714\n",
      " 0.32809524 0.23285714 0.85714286 0.53444444 0.35714286 0.30031746\n",
      " 0.55285714 0.3147619  0.08063492 0.20904762 0.27777778 0.67857143\n",
      " 0.46428571 0.13619048 0.30285714 0.42190476 0.26587302 0.62031746\n",
      " 0.52253968 0.70761905 0.37428571 0.14809524 0.3015873  0.87174603\n",
      " 0.22619048 0.48015873 0.17984127 0.28968254 0.74333333 0.42984127\n",
      " 0.08857143 0.43777778 0.67063492 0.57269841 0.1415873  0.21031746\n",
      " 0.19571429 0.07412698 0.11904762 0.68777778 0.13761905 0.55555556\n",
      " 0.41666667 0.42587302 0.2368254  0.3068254  0.12031746 0.44444444\n",
      " 0.32936508 0.54634921 0.21952381 0.16396825 0.3584127  0.34396825\n",
      " 0.40873016 0.40603175 0.16793651 0.73539683 0.66936508 0.63761905\n",
      " 0.08206349 0.57666667 0.82015873 0.06079365 0.06873016 0.09396825\n",
      " 0.18126984 0.31349206 0.70904762 0.19714286 0.4615873  0.38761905\n",
      " 0.10714286 0.54761905 0.23142857 0.07539683 0.49603175 0.42063492\n",
      " 0.43920635 0.0647619  0.07015873 0.09920635 0.60984127 0.58730159\n",
      " 0.05285714 0.07269841 0.72888889 0.06746032 0.26857143 0.07666667\n",
      " 0.03968254 0.11777778 0.06222222 0.04365079 0.25       0.12698413\n",
      " 0.07142857 0.34920635 0.03698413 0.87968254 0.30428571 0.04095238\n",
      " 0.13365079 0.69571429 0.03444444 0.28571429 0.17587302 0.08333333\n",
      " 0.05952381 0.31619048 0.26063492 0.33460317 0.30952381 0.18253968\n",
      " 0.33333333 0.53301587 0.40206349 0.46031746 0.39952381 0.77777778\n",
      " 0.20634921 0.78698413 0.26984127 0.03571429 0.09126984 0.29634921\n",
      " 0.26190476 0.20761905 0.05031746 0.16936508 0.40746032 0.15603175\n",
      " 0.12174603 0.30555556 0.19968254 0.1984127  0.11238095 0.46698413\n",
      " 0.68380952 0.02253968 0.2552381  0.27380952 0.60587302 0.88492063\n",
      " 0.09253968 0.13492063 0.3915873  0.20365079 0.33730159 0.24873016\n",
      " 0.56222222 0.60444444 0.7115873  0.62825397 0.21301587 0.1931746\n",
      " 0.26714286 0.05555556 0.21555556 0.36111111 0.61380952 0.35587302\n",
      " 0.12968254 0.36238095 0.27507937 0.26460317 0.11634921 0.05825397\n",
      " 0.40349206 0.0568254  0.15873016 0.33206349 0.96952381 0.22888889\n",
      " 0.53174603 0.16539683 0.4047619  0.40079365 0.79888889 0.27904762\n",
      " 0.11507937 0.         0.51190476 0.1031746  0.74873016 0.25793651\n",
      " 0.14412698 0.49873016 0.44174603 0.66666667 0.18380952 0.28698413\n",
      " 0.32015873 0.17730159 0.25920635 0.54888889 1.         0.59650794\n",
      " 0.44714286 0.25126984 0.29238095 0.59793651 0.45111111 0.46555556\n",
      " 0.72619048 0.81619048 0.10444444 0.29365079 0.5515873  0.22746032\n",
      " 0.94714286 0.60047619 0.39555556 0.5131746  0.10047619 0.0384127\n",
      " 0.54095238 0.13095238 0.39015873 0.12428571 0.35444444 0.3968254\n",
      " 0.34650794 0.28301587 0.18777778 0.03174603 0.06619048 0.2631746\n",
      " 0.53047619 0.19174603 0.57936508 0.35984127]\n",
      "A3 : [0.         0.15928571 0.01785714 0.055      0.20089286 0.14285714\n",
      " 0.03714286 0.41375    0.17553571 0.02964286 0.06553571 0.21428571\n",
      " 0.21571429 0.375      0.15767857 0.03125    0.20982143 0.00892857\n",
      " 0.30660714 0.40178571 0.03571429 0.28571429 0.51785714 0.23214286\n",
      " 0.02089286 0.46428571 0.66071429 0.30357143 0.52821429 0.34964286\n",
      " 0.27089286 0.18303571 0.38392857 0.05357143 0.05660714 0.41964286\n",
      " 0.33625    0.3275     0.53571429 0.05053571 0.49696429 1.\n",
      " 0.24107143 0.07285714 0.02375    0.08928571 0.10714286 0.41517857\n",
      " 0.16071429 0.4375     0.57732143 0.02821429 0.02982143 0.15178571\n",
      " 0.01339286 0.89732143 0.26785714 0.17857143 0.25       0.18892857\n",
      " 0.04160714 0.34821429 0.67857143 0.02232143 0.07892857 0.45535714\n",
      " 0.55357143 0.04910714 0.12642857 0.39285714 0.0625     0.58928571\n",
      " 0.42857143 0.08035714 0.02678571 0.125      0.44642857 0.04464286\n",
      " 0.04017857 0.25142857 0.36910714 0.22178571 0.23803571 0.32142857\n",
      " 0.19642857 0.01928571 0.09821429 0.33928571 0.48214286 0.13392857\n",
      " 0.57142857 0.01035714 0.05946429 0.26928571 0.01642857 0.35714286\n",
      " 0.41071429 0.10857143 0.07142857 0.00285714 0.06107143 0.11607143\n",
      " 0.09071429 0.48517857 0.30946429 0.33035714 0.29178571 0.08339286\n",
      " 0.69642857 0.20232143 0.16517857 0.00732143 0.03428571 0.14428571\n",
      " 0.18       0.11303571 0.27232143 0.35857143 0.36607143 0.07589286\n",
      " 0.33339286 0.23660714 0.09678571 0.34375    0.44785714 0.34071429\n",
      " 0.30214286 0.49107143 0.75       0.36160714 0.89589286 0.0075\n",
      " 0.76785714 0.39732143 0.39446429 0.04767857 0.00303571 0.04321429\n",
      " 0.00589286 0.20392857 0.19339286 0.45089286 0.02071429 0.01482143\n",
      " 0.08625    0.01196429 0.11160714 0.43303571 0.10267857 0.48803571\n",
      " 0.94053571 0.3675     0.04607143 0.78571429 0.00446429 0.03875\n",
      " 0.14589286 0.16821429 0.22017857 0.16375    0.40928571 0.52089286\n",
      " 0.00607143 0.05803571 0.07446429 0.18160714 0.10125    0.06392857\n",
      " 0.02517857 0.07732143 0.08178571 0.64732143 0.11017857 0.41660714\n",
      " 0.14732143 0.03857143 0.47625    0.42267857 0.17107143 0.35571429\n",
      " 0.25285714 0.90035714 0.02392857 0.13535714 0.79607143 0.11910714\n",
      " 0.015      0.05214286 0.00142857 0.44035714 0.44053571 0.03267857\n",
      " 0.5        0.63392857 0.71428571 0.1875     0.14875    0.38982143\n",
      " 0.16964286 0.37196429 0.02535714 0.08785714 0.34232143 0.12946429\n",
      " 0.09517857 0.20839286 0.45839286 0.38089286 0.25892857 0.36464286\n",
      " 0.1175     0.36017857 0.12053571]\n",
      "A4 : [1 2 0]\n",
      "A5 : [0 2 1]\n",
      "A6 : [12 10  9 11  2  8  1  3 13  6  4  0  5  7]\n",
      "A7 : [7 3 0 2 4 8 6 1 5]\n",
      "A8 : [0.04385965 0.10666667 0.05263158 0.13157895 0.06       0.0877193\n",
      " 0.22807018 0.00140351 0.13894737 0.11105263 0.07596491 0.15210526\n",
      " 0.03508772 0.1754386  0.00877193 0.03368421 0.11122807 0.02333333\n",
      " 0.02631579 0.02929825 0.27631579 0.10824561 0.01754386 0.18122807\n",
      " 0.52631579 0.24561404 0.17684211 0.27929825 0.26614035 0.0145614\n",
      " 0.07017544 0.06438596 0.50578947 0.15789474 0.18719298 0.30263158\n",
      " 1.         0.09210526 0.00438596 0.21192982 0.12280702 0.00578947\n",
      " 0.03070175 0.06140351 0.         0.26017544 0.00298246 0.20175439\n",
      " 0.21052632 0.10526316 0.05561404 0.15052632 0.05403509 0.05122807\n",
      " 0.05701754 0.47368421 0.37719298 0.01315789 0.02052632 0.01596491\n",
      " 0.14035088 0.33192982 0.07894737 0.35087719 0.02789474 0.04824561\n",
      " 0.04526316 0.40350877 0.22070175 0.49122807 0.01175439 0.04245614\n",
      " 0.25877193 0.29824561 0.26315789 0.11403509 0.45614035 0.19298246\n",
      " 0.14912281 0.02192982 0.17842105 0.09649123 0.08333333 0.28070175\n",
      " 0.03807018 0.08912281 0.14614035 0.05842105 0.38596491 0.31578947\n",
      " 0.04684211 0.04964912 0.06877193 0.09070175 0.43859649 0.17982456\n",
      " 0.54385965 0.02491228 0.19877193 0.63157895 0.18421053 0.30403509\n",
      " 0.08035088 0.70175439 0.08631579 0.48684211 0.07315789 0.16070175\n",
      " 0.07157895 0.01017544 0.01614035 0.00736842 0.01894737 0.11701754\n",
      " 0.08192982 0.04087719 0.08473684 0.09789474 0.1622807  0.03649123\n",
      " 0.16666667 0.23684211 0.06578947 0.56140351 0.44736842 0.18859649\n",
      " 0.0745614  0.61403509 0.10964912 0.0277193  0.29087719]\n",
      "A9 : [1 0]\n",
      "A10 : [1 0]\n",
      "A11 : [ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n",
      "A12 : [0 1]\n",
      "A13 : [0 2 1]\n",
      "A14 : [0.101  0.0215 0.14   0.05   0.06   0.18   0.082  0.04   0.09   0.026\n",
      " 0.064  0.13   0.     0.16   0.198  0.048  0.1    0.15   0.0725 0.25\n",
      " 0.084  0.217  0.2915 0.015  0.12   0.035  0.2275 0.1555 0.108  0.2455\n",
      " 0.2    0.1195 0.08   0.3555 0.125  0.26   0.2575 0.21   0.49   0.2215\n",
      " 0.07   0.047  0.184  0.144  0.094  0.056  0.0855 0.134  0.0835 0.0375\n",
      " 0.076  0.088  0.1645 0.106  0.205  0.137  0.1875 0.204  0.175  0.102\n",
      " 0.02   0.0905 0.1995 0.22   0.0465 0.03   0.1975 0.1965 0.0105 0.0145\n",
      " 0.051  0.2155 0.185  0.012  0.01   0.0645 0.255  0.0975 0.072  0.19\n",
      " 0.0245 0.025  0.1905 0.075  0.0585 0.028  0.1055 0.115  0.078  0.011\n",
      " 0.114  0.2595 0.1265 0.2435 0.11   0.044  0.0605 0.235  0.068  0.066\n",
      " 0.146  0.077  0.136  0.17   0.054  0.36   0.225  0.116  0.085  0.23\n",
      " 0.174  0.24   0.32   0.138  0.1105 0.176  0.0705 0.089  0.3    0.275\n",
      " 0.0365 1.     0.1125 0.105  0.055  0.178  0.0225 0.031  0.046  0.087\n",
      " 0.0085 0.043  0.227  0.127  0.014  0.1665 0.156  0.1855 0.0495 0.126\n",
      " 0.38   0.28   0.065  0.2615 0.34   0.0815 0.104  0.1915 0.165  0.211\n",
      " 0.145  0.42   0.216  0.016  0.093  0.1515 0.1745 0.112  0.1845 0.038\n",
      " 0.1155 0.1545 0.208  0.2325]\n",
      "A15 : [0.0000e+00 5.6000e-03 8.2400e-03 3.0000e-05 3.1285e-01 1.3490e-02\n",
      " 3.1400e-03 1.4420e-02 2.0000e-03 2.6900e-02 2.4500e-03 1.2080e-02\n",
      " 1.2600e-02 1.1000e-04 1.0000e-01 5.0000e-02 4.0000e-02 3.5000e-04\n",
      " 7.1300e-03 5.5100e-03 5.0000e-03 3.0000e-03 2.2100e-03 2.2830e-02\n",
      " 1.0000e-03 1.5000e-04 2.8400e-03 1.2360e-02 5.8000e-02 7.3000e-03\n",
      " 4.0000e-03 5.0000e-01 4.5600e-03 1.5108e-01 2.9540e-02 2.0000e-05\n",
      " 2.0000e-04 2.7000e-04 2.2500e-03 1.0000e-05 3.8000e-04 5.0000e-05\n",
      " 1.3000e-03 1.4700e-03 2.1000e-03 1.1202e-01 1.3320e-02 5.0000e-04\n",
      " 2.5800e-03 5.6700e-03 1.0000e-02 2.5100e-02 8.0900e-03 6.1000e-03\n",
      " 1.5000e-03 5.1100e-01 3.6700e-03 6.0000e-03 2.4700e-03 3.7500e-03\n",
      " 2.7800e-03 8.2700e-03 2.0720e-02 5.8200e-03 2.3000e-02 3.0650e-02\n",
      " 2.2000e-02 6.0000e-05 1.6020e-02 2.1840e-02 3.3760e-02 2.0000e-02\n",
      " 7.5440e-02 1.0561e-01 8.3700e-03 1.1177e-01 6.3900e-03 2.0280e-02\n",
      " 1.0650e-02 5.4000e-03 1.5800e-03 1.5000e-01 3.0000e-02 3.2570e-02\n",
      " 1.6550e-02 1.4300e-02 7.0000e-05 7.9000e-03 3.9600e-03 6.7800e-03\n",
      " 1.1870e-02 6.5900e-02 1.6800e-03 1.2700e-02 1.2100e-02 7.4200e-03\n",
      " 8.8510e-02 7.0590e-02 1.7040e-02 8.5700e-03 6.7000e-02 2.5030e-02\n",
      " 9.8000e-02 1.9600e-03 1.4000e-04 1.8027e-01 9.9000e-04 1.2000e-02\n",
      " 1.3000e-04 1.2000e-03 3.2000e-04 7.2200e-03 4.0000e-04 4.8400e-03\n",
      " 2.0400e-03 9.8000e-04 5.5520e-02 2.8030e-02 4.4400e-03 1.2600e-03\n",
      " 4.0000e-05 2.1000e-04 1.7300e-03 1.0000e-04 2.5000e-04 4.2000e-04\n",
      " 1.0000e+00 1.1300e-03 8.0000e-05 4.4000e-04 2.7320e-02 1.7900e-03\n",
      " 1.6000e-04 1.0620e-02 2.5100e-03 2.2800e-03 6.7000e-04 1.2000e-04\n",
      " 4.2080e-02 1.3000e-02 1.1200e-03 1.1100e-02 2.8600e-03 4.5000e-02\n",
      " 1.2120e-02 1.9500e-03 8.7000e-04 1.7000e-04 1.8400e-03 1.4000e-03\n",
      " 1.4600e-03 2.2000e-04 5.5000e-04 7.0000e-04 6.0000e-04 1.0580e-02\n",
      " 7.6900e-03 1.9000e-04 3.1600e-03 3.5000e-03 3.5520e-02 6.8700e-03\n",
      " 1.9500e-02 1.8000e-04 5.3000e-04 4.1000e-04 3.3000e-04 8.0000e-04\n",
      " 3.5100e-03 2.1000e-02 4.7500e-03 8.9200e-03 4.6070e-02 2.2060e-02\n",
      " 5.8600e-02 2.8000e-04 1.3910e-02 5.9100e-03 9.6000e-03 6.9000e-03\n",
      " 8.0000e-03 9.9000e-03 2.1970e-02 9.0000e-04 3.4700e-03 3.2700e-03\n",
      " 4.0710e-02 1.0900e-03 1.2490e-02 1.3400e-03 1.3440e-02 3.2100e-03\n",
      " 9.4800e-03 2.0790e-02 2.3840e-02 4.5800e-03 5.2980e-02 1.6200e-03\n",
      " 1.5830e-02 5.8000e-04 5.9000e-04 1.4000e-02 1.4650e-02 8.0000e-02\n",
      " 4.7000e-02 1.0970e-02 3.2900e-02 1.3212e-01 5.7770e-02 5.1240e-02\n",
      " 2.3000e-04 4.1590e-02 9.1800e-03 2.8300e-03 1.0800e-03 9.0000e-05\n",
      " 6.8000e-04 5.8700e-03 5.0100e-03 1.6000e-03 3.9000e-03 1.5400e-03\n",
      " 1.1700e-03 2.4600e-03 2.3700e-03 3.6400e-03 5.3700e-03 3.9400e-03\n",
      " 7.5000e-03]\n",
      "T : [1 0]\n"
     ]
    }
   ],
   "source": [
    "for column in df1:\n",
    "    print(f'{column} : {df1[column].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f83a64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashan_105579\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df1.drop('A14',axis='columns',inplace=True)\n",
    "\n",
    "X = df1.drop('T',axis='columns')\n",
    "y = df1['T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "662ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7de8cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b8311bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def train(X_train, y_train):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(\n",
    "            14, \n",
    "            input_shape=(14,),\n",
    "            activation='relu',\n",
    "            activity_regularizer=regularizers.l2(1e-2)\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            4,\n",
    "            activation='relu',\n",
    "            activity_regularizer=regularizers.l2(1e-2)\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            1, \n",
    "            activation='sigmoid'\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['Precision', 'Recall'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=50,verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eb7c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abaa04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, X_test):\n",
    "    yp = model.predict(X_test)\n",
    "    y_pred = []\n",
    "    for element in yp:\n",
    "        if element > 0.5:\n",
    "            y_pred.append(1)\n",
    "        else:\n",
    "            y_pred.append(0)\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7d97a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "def report(y_test, y_pred):\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "773f9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def f1score(y_test, y_pred):\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f1)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4d46e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelF1(X_train, y_train, X_test, y_test):\n",
    "    print(' ------------ Training --------------')\n",
    "    model = train(X_train, y_train)\n",
    "    print(' ------------ Evaluation --------------')\n",
    "    evaluate(model, X_test, y_test)\n",
    "    print(' ------------ Prediction --------------')\n",
    "    y_pred = prediction(model, X_test)\n",
    "    print(' ------------ Report --------------')\n",
    "#     report(y_test, y_pred)\n",
    "    print(' ------------ F1-Score --------------')\n",
    "    return f1score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "32a59074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------ Training --------------\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 873us/step - loss: 0.8240 - precision: 0.5545 - recall: 0.2373\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.6366 - precision: 0.8220 - recall: 0.4110\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.5370 - precision: 0.8205 - recall: 0.6780\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.4374 - precision: 0.8494 - recall: 0.8602\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3489 - precision: 0.8599 - recall: 0.9364\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3067 - precision: 0.8814 - recall: 0.9449\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2940 - precision: 0.8880 - recall: 0.9407\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 875us/step - loss: 0.2772 - precision: 0.8880 - recall: 0.9407\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2683 - precision: 0.8939 - recall: 0.9280\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2694 - precision: 0.8880 - recall: 0.9407\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2774 - precision: 0.9076 - recall: 0.9153\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2603 - precision: 0.8907 - recall: 0.9322\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2571 - precision: 0.9016 - recall: 0.9322\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2717 - precision: 0.9028 - recall: 0.9449\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2601 - precision: 0.8992 - recall: 0.9449\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2392 - precision: 0.9061 - recall: 0.9407\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2397 - precision: 0.9057 - recall: 0.9364\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2361 - precision: 0.8996 - recall: 0.9492\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2433 - precision: 0.9185 - recall: 0.9068\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2264 - precision: 0.9202 - recall: 0.9280\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2333 - precision: 0.9046 - recall: 0.9237\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2274 - precision: 0.9160 - recall: 0.9237\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 1000us/step - loss: 0.2232 - precision: 0.9132 - recall: 0.9364\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2262 - precision: 0.9167 - recall: 0.9322\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2247 - precision: 0.9177 - recall: 0.9449\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2259 - precision: 0.9121 - recall: 0.9237\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2391 - precision: 0.9274 - recall: 0.9195\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2315 - precision: 0.9170 - recall: 0.9364\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2226 - precision: 0.9244 - recall: 0.9322\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2215 - precision: 0.9270 - recall: 0.9153\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2176 - precision: 0.9132 - recall: 0.9364\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2089 - precision: 0.9150 - recall: 0.9576\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2207 - precision: 0.9132 - recall: 0.9364\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2258 - precision: 0.9061 - recall: 0.9407\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2332 - precision: 0.9083 - recall: 0.9237\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 937us/step - loss: 0.2160 - precision: 0.9040 - recall: 0.9576\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2241 - precision: 0.9036 - recall: 0.9534\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2399 - precision: 0.8858 - recall: 0.9534\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2222 - precision: 0.9277 - recall: 0.9237\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2101 - precision: 0.9277 - recall: 0.9237\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2191 - precision: 0.9076 - recall: 0.9576\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2088 - precision: 0.9069 - recall: 0.9492\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2026 - precision: 0.9036 - recall: 0.9534\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2106 - precision: 0.9028 - recall: 0.9449\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2102 - precision: 0.9036 - recall: 0.9534\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2106 - precision: 0.9095 - recall: 0.9364\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2075 - precision: 0.9106 - recall: 0.9492\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2166 - precision: 0.8960 - recall: 0.9492\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2088 - precision: 0.9061 - recall: 0.9407\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2027 - precision: 0.9080 - recall: 0.9619\n",
      " ------------ Evaluation --------------\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.9615 - precision: 0.5806 - recall: 0.9000\n",
      " ------------ Prediction --------------\n",
      " ------------ Report --------------\n",
      " ------------ F1-Score --------------\n",
      "0.7058823529411764\n",
      " ------------ Training --------------\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 811us/step - loss: 0.8870 - precision: 0.5606 - recall: 0.6245\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.6755 - precision: 0.7737 - recall: 0.4473\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.6290 - precision: 0.7406 - recall: 0.6624\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.5834 - precision: 0.7665 - recall: 0.7342\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.5254 - precision: 0.7814 - recall: 0.8143\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.4852 - precision: 0.8122 - recall: 0.8397\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 937us/step - loss: 0.4566 - precision: 0.7917 - recall: 0.8819\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.4275 - precision: 0.8273 - recall: 0.8692\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.4126 - precision: 0.8247 - recall: 0.8734\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.4047 - precision: 0.8132 - recall: 0.8819\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3953 - precision: 0.8161 - recall: 0.8987\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 999us/step - loss: 0.3936 - precision: 0.8252 - recall: 0.8565\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 933us/step - loss: 0.3854 - precision: 0.8196 - recall: 0.8819\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3800 - precision: 0.8353 - recall: 0.8776\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3926 - precision: 0.8207 - recall: 0.8692\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3692 - precision: 0.8307 - recall: 0.8903\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3686 - precision: 0.8273 - recall: 0.8692\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.3627 - precision: 0.8360 - recall: 0.8819\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3656 - precision: 0.8288 - recall: 0.8987\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3976 - precision: 0.8286 - recall: 0.8565\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3723 - precision: 0.8125 - recall: 0.8776\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3749 - precision: 0.8500 - recall: 0.8608\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.3700 - precision: 0.8294 - recall: 0.8819\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 998us/step - loss: 0.3633 - precision: 0.8373 - recall: 0.8903\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.3790 - precision: 0.8200 - recall: 0.8650\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3768 - precision: 0.8397 - recall: 0.8397\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3747 - precision: 0.8306 - recall: 0.8692\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3713 - precision: 0.8415 - recall: 0.8734\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3625 - precision: 0.8346 - recall: 0.8945\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3568 - precision: 0.8425 - recall: 0.9030\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3554 - precision: 0.8340 - recall: 0.8903\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3656 - precision: 0.8333 - recall: 0.8861\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3532 - precision: 0.8462 - recall: 0.8819\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.3505 - precision: 0.8480 - recall: 0.8945\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.3613 - precision: 0.8281 - recall: 0.8945\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3517 - precision: 0.8386 - recall: 0.8987\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3483 - precision: 0.8367 - recall: 0.8861\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3408 - precision: 0.8458 - recall: 0.9030\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3441 - precision: 0.8392 - recall: 0.9030\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3599 - precision: 0.8361 - recall: 0.8608\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3451 - precision: 0.8519 - recall: 0.8734\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3416 - precision: 0.8601 - recall: 0.8819\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3457 - precision: 0.8502 - recall: 0.8861\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3417 - precision: 0.8496 - recall: 0.8819\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 860us/step - loss: 0.3436 - precision: 0.8462 - recall: 0.8819\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3407 - precision: 0.8455 - recall: 0.8776\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 813us/step - loss: 0.3479 - precision: 0.8394 - recall: 0.8819\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3690 - precision: 0.8374 - recall: 0.8692\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3592 - precision: 0.8242 - recall: 0.8903\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.3512 - precision: 0.8327 - recall: 0.9030\n",
      " ------------ Evaluation --------------\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.1934 - precision: 0.9825 - recall: 0.9492\n",
      " ------------ Prediction --------------\n",
      " ------------ Report --------------\n",
      " ------------ F1-Score --------------\n",
      "0.9655172413793103\n",
      " ------------ Training --------------\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 810us/step - loss: 0.9515 - precision: 0.7273 - recall: 0.5738\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.6549 - precision: 0.8417 - recall: 0.4937\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 875us/step - loss: 0.6045 - precision: 0.8408 - recall: 0.5570\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.5610 - precision: 0.8000 - recall: 0.7257\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.5041 - precision: 0.8194 - recall: 0.7848\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4607 - precision: 0.7946 - recall: 0.8650\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.4363 - precision: 0.7937 - recall: 0.8439\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.4498 - precision: 0.7802 - recall: 0.8987\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 998us/step - loss: 0.4091 - precision: 0.8072 - recall: 0.8481\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3940 - precision: 0.8196 - recall: 0.8819\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4032 - precision: 0.8154 - recall: 0.8945\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3809 - precision: 0.8300 - recall: 0.8650\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3806 - precision: 0.8287 - recall: 0.8776\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.4366 - precision: 0.7778 - recall: 1.00 - 0s 997us/step - loss: 0.3761 - precision: 0.8263 - recall: 0.9030\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3694 - precision: 0.8224 - recall: 0.8987\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3755 - precision: 0.8584 - recall: 0.8439\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3782 - precision: 0.8306 - recall: 0.8481\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.3718 - precision: 0.8127 - recall: 0.9156\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3693 - precision: 0.8481 - recall: 0.8481\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3594 - precision: 0.8228 - recall: 0.8819\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3554 - precision: 0.8148 - recall: 0.9283\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3491 - precision: 0.8206 - recall: 0.9072\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.3466 - precision: 0.8165 - recall: 0.9198\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3520 - precision: 0.8134 - recall: 0.9198\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3515 - precision: 0.8175 - recall: 0.9072\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3459 - precision: 0.8127 - recall: 0.9156\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.3461 - precision: 0.8213 - recall: 0.9114\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 952us/step - loss: 0.3521 - precision: 0.8458 - recall: 0.9030\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 999us/step - loss: 0.3439 - precision: 0.8421 - recall: 0.8776\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3340 - precision: 0.8340 - recall: 0.8903\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3343 - precision: 0.8419 - recall: 0.8987\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.3360 - precision: 0.8327 - recall: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3279 - precision: 0.8202 - recall: 0.9241\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3334 - precision: 0.8514 - recall: 0.8945\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3366 - precision: 0.8496 - recall: 0.8819\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3358 - precision: 0.8366 - recall: 0.9072\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3370 - precision: 0.8406 - recall: 0.8903\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3453 - precision: 0.8490 - recall: 0.8776\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.3330 - precision: 0.8449 - recall: 0.8734\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3376 - precision: 0.8462 - recall: 0.8819\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3313 - precision: 0.8425 - recall: 0.9030\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3463 - precision: 0.8696 - recall: 0.8439\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.3392 - precision: 0.8536 - recall: 0.8608\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3463 - precision: 0.8275 - recall: 0.8903\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.3595 - precision: 0.7855 - recall: 0.9114\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3462 - precision: 0.8340 - recall: 0.8903\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3361 - precision: 0.8761 - recall: 0.8650\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3341 - precision: 0.8449 - recall: 0.8734\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3295 - precision: 0.8400 - recall: 0.8861\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3274 - precision: 0.8386 - recall: 0.8987\n",
      " ------------ Evaluation --------------\n",
      "5/5 [==============================] - 0s 745us/step - loss: 0.3464 - precision: 1.0000 - recall: 0.8136\n",
      " ------------ Prediction --------------\n",
      " ------------ Report --------------\n",
      " ------------ F1-Score --------------\n",
      "0.897196261682243\n",
      " ------------ Training --------------\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 811us/step - loss: 1.1953 - precision: 0.5765 - recall: 0.6835\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.6765 - precision: 0.7754 - recall: 0.6118\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.5897 - precision: 0.8141 - recall: 0.6835\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.5103 - precision: 0.8282 - recall: 0.7932\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.4406 - precision: 0.8553 - recall: 0.8228\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 932us/step - loss: 0.3995 - precision: 0.8696 - recall: 0.8439\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 937us/step - loss: 0.3546 - precision: 0.8917 - recall: 0.9030\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3396 - precision: 0.8852 - recall: 0.9114\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3234 - precision: 0.8765 - recall: 0.8987\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3098 - precision: 0.8835 - recall: 0.9283\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3057 - precision: 0.8735 - recall: 0.9325\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 1000us/step - loss: 0.2917 - precision: 0.8871 - recall: 0.9283\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2854 - precision: 0.8884 - recall: 0.9409\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - ETA: 0s - loss: 0.2519 - precision: 0.8182 - recall: 0.90 - 0s 935us/step - loss: 0.2882 - precision: 0.8967 - recall: 0.9156\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2731 - precision: 0.9069 - recall: 0.9451\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.2673 - precision: 0.8920 - recall: 0.9409\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2652 - precision: 0.9020 - recall: 0.9325\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2575 - precision: 0.8956 - recall: 0.9409\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2634 - precision: 0.9136 - recall: 0.9367\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 875us/step - loss: 0.2684 - precision: 0.8992 - recall: 0.9409\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2873 - precision: 0.9079 - recall: 0.9156\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2701 - precision: 0.9053 - recall: 0.9283\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2602 - precision: 0.9095 - recall: 0.9325\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2792 - precision: 0.8975 - recall: 0.9241\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 998us/step - loss: 0.2542 - precision: 0.9024 - recall: 0.9367\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.2542 - precision: 0.9121 - recall: 0.9198\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2480 - precision: 0.9098 - recall: 0.9367\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2486 - precision: 0.9247 - recall: 0.9325\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2499 - precision: 0.9008 - recall: 0.9198\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2555 - precision: 0.8992 - recall: 0.9409\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2420 - precision: 0.9020 - recall: 0.9325\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.2610 - precision: 0.8866 - recall: 0.9241\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2471 - precision: 0.9170 - recall: 0.9325\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2478 - precision: 0.9095 - recall: 0.9325\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2722 - precision: 0.9016 - recall: 0.9283\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2747 - precision: 0.9012 - recall: 0.9241\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2457 - precision: 0.8988 - recall: 0.9367\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2448 - precision: 0.9132 - recall: 0.9325\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.2482 - precision: 0.9132 - recall: 0.9325\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2665 - precision: 0.8984 - recall: 0.9325\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.2613 - precision: 0.9061 - recall: 0.9367\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2330 - precision: 0.9102 - recall: 0.9409\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.2314 - precision: 0.8992 - recall: 0.9409\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2474 - precision: 0.9136 - recall: 0.9367\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2502 - precision: 0.9091 - recall: 0.9283\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2426 - precision: 0.9016 - recall: 0.9283\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2392 - precision: 0.9012 - recall: 0.9241\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 997us/step - loss: 0.2409 - precision: 0.9028 - recall: 0.9409\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2460 - precision: 0.9202 - recall: 0.9241\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.2314 - precision: 0.9136 - recall: 0.9367\n",
      " ------------ Evaluation --------------\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6432 - precision: 0.7077 - recall: 0.7797\n",
      " ------------ Prediction --------------\n",
      " ------------ Report --------------\n",
      " ------------ F1-Score --------------\n",
      "0.7419354838709677\n",
      " ------------ Training --------------\n",
      "Epoch 1/50\n",
      "17/17 [==============================] - 1s 748us/step - loss: 1.1772 - precision: 0.4688 - recall: 0.9198\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.6941 - precision: 0.7213 - recall: 0.5570\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.6198 - precision: 0.7389 - recall: 0.6329\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.5610 - precision: 0.7848 - recall: 0.7384\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.5066 - precision: 0.7614 - recall: 0.8481\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.4690 - precision: 0.8072 - recall: 0.8481\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.4465 - precision: 0.8088 - recall: 0.8565\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.4132 - precision: 0.8125 - recall: 0.8776\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.4087 - precision: 0.8125 - recall: 0.8776\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.4024 - precision: 0.8266 - recall: 0.8650\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 0s 936us/step - loss: 0.3754 - precision: 0.8185 - recall: 0.9325\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 0s 937us/step - loss: 0.3946 - precision: 0.8259 - recall: 0.8608\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3741 - precision: 0.8566 - recall: 0.8819\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3567 - precision: 0.8320 - recall: 0.8987\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3534 - precision: 0.8458 - recall: 0.9030\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 0s 808us/step - loss: 0.3593 - precision: 0.8525 - recall: 0.8776\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 0s 685us/step - loss: 0.3611 - precision: 0.8548 - recall: 0.8692\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3479 - precision: 0.8289 - recall: 0.9198\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3450 - precision: 0.8776 - recall: 0.8776\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3494 - precision: 0.8462 - recall: 0.8819\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3524 - precision: 0.8571 - recall: 0.8861\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3410 - precision: 0.8577 - recall: 0.9156\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3541 - precision: 0.8374 - recall: 0.8692\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3388 - precision: 0.8398 - recall: 0.9072\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3270 - precision: 0.8669 - recall: 0.9072\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 0s 811us/step - loss: 0.3294 - precision: 0.8623 - recall: 0.8987\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3217 - precision: 0.8606 - recall: 0.9114\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 0s 747us/step - loss: 0.3381 - precision: 0.8601 - recall: 0.8819\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3220 - precision: 0.8600 - recall: 0.9072\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3271 - precision: 0.8694 - recall: 0.8987\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3168 - precision: 0.8730 - recall: 0.8987\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3193 - precision: 0.8571 - recall: 0.9114\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3181 - precision: 0.8589 - recall: 0.8987\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3223 - precision: 0.8765 - recall: 0.8987\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3536 - precision: 0.8565 - recall: 0.8565\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3301 - precision: 0.8644 - recall: 0.8608\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 0s 809us/step - loss: 0.3258 - precision: 0.8555 - recall: 0.9241\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3169 - precision: 0.8694 - recall: 0.8987\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 0s 748us/step - loss: 0.3110 - precision: 0.8699 - recall: 0.9030\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3065 - precision: 0.8750 - recall: 0.9156\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3020 - precision: 0.8622 - recall: 0.9241\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2977 - precision: 0.8811 - recall: 0.9072\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2969 - precision: 0.8617 - recall: 0.9198\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3149 - precision: 0.8600 - recall: 0.9072\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3223 - precision: 0.8648 - recall: 0.8903\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3124 - precision: 0.8802 - recall: 0.8987\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3132 - precision: 0.8694 - recall: 0.8987\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 0s 844us/step - loss: 0.3069 - precision: 0.8577 - recall: 0.8903\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 0s 872us/step - loss: 0.2878 - precision: 0.8821 - recall: 0.9156\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 0s 810us/step - loss: 0.3038 - precision: 0.8735 - recall: 0.9030\n",
      " ------------ Evaluation --------------\n",
      "5/5 [==============================] - 0s 994us/step - loss: 0.2378 - precision: 0.9464 - recall: 0.8983\n",
      " ------------ Prediction --------------\n",
      " ------------ Report --------------\n",
      " ------------ F1-Score --------------\n",
      "0.9217391304347826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.846454094061696"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "f1_total = 0\n",
    "for train_index, test_index in folds.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    f1_total = f1_total + modelF1(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "f1_avg = f1_total / 5\n",
    "f1_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8028e679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
